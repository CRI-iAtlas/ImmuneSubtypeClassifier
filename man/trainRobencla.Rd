% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/trainRobencla.R
\name{trainRobencla}
\alias{trainRobencla}
\title{Train a Robencla Classifier for Immune Subtype Classification}
\usage{
trainRobencla(
  data,
  label_name = "ClusterLabel",
  sample_id = "SampleBarcode",
  pair_list,
  max_depth = 12,
  eta = 0.3,
  nrounds = 64,
  early_stopping_rounds = 2,
  nthreads = 4,
  gamma = 0.2,
  lambda = 1.2,
  alpha = 0.2,
  ensemble_size = 11,
  sample_prop = 0.8,
  feature_prop = 0.8,
  subsample = 0.8,
  combine_function = "median",
  verbose = 0,
  trim_model = TRUE
)
}
\arguments{
\item{data}{A data.frame containing the training data with features,
labels, and sample identifiers.}

\item{label_name}{Character string specifying the column name containing
class labels. Default is "ClusterLabel".}

\item{sample_id}{Character string specifying the column name containing
sample identifiers. Default is "SampleBarcode".}

\item{pair_list}{A named list where each element corresponds to a class
and contains a character vector of feature names. Features are paired
sequentially (1-2, 3-4, 5-6, ...) for named pair transformation.}

\item{max_depth}{Integer, maximum tree depth. Higher values increase
model complexity. Default is 12.}

\item{eta}{Numeric, learning rate. Smaller values are more conservative.
Default is 0.3.}

\item{nrounds}{Integer, maximum number of boosting rounds. Default is 64.}

\item{early_stopping_rounds}{Integer, training stops if performance
doesn't improve for this many rounds. Default is 2.}

\item{nthreads}{Integer, number of parallel threads. Default is 4.}

\item{gamma}{Numeric, minimum loss reduction required to make a split.
Higher values are more conservative. Default is 0.2.}

\item{lambda}{Numeric, L2 regularization term on weights. Default is 1.2.}

\item{alpha}{Numeric, L1 regularization term on weights. Default is 0.2.}

\item{ensemble_size}{Integer, number of models in each class ensemble.
Default is 11.}

\item{sample_prop}{Numeric, proportion of samples used to train each
ensemble member. Default is 0.8.}

\item{feature_prop}{Numeric, proportion of features used to train each
ensemble member. Default is 0.8.}

\item{subsample}{Numeric, XGBoost subsample ratio of training instances.
Default is 0.8.}

\item{combine_function}{Character, method for combining ensemble
predictions. Currently only "median" is supported. Default is "median".}

\item{verbose}{Integer, verbosity level. 0 for silent. Default is 0.}

\item{trim_model}{Logical, whether to call trim() on the model after
training to reduce object size. Default is TRUE.}
}
\value{
A trained Robencla model object.
}
\description{
Trains a robencla ensemble classifier using named feature pairs and
XGBoost parameters tuned for immune subtype prediction.
}
\details{
The classifier uses named feature pairs (namedpairs mode) where features
are paired sequentially within each class's pair_list. XGBoost parameters
are tuned for immune subtype classification tasks.

For more information on XGBoost parameters, see:
\url{https://xgboost.readthedocs.io/en/latest/parameter.html}
}
\examples{
\dontrun{
# Define feature pairs for each class
pair_list <- list(
  C1 = c("GeneA", "GeneB", "GeneC", "GeneD"),
  C2 = c("GeneE", "GeneF", "GeneG", "GeneH")
)

# Train the classifier
model <- trainRobencla(
  data = training_data,
  label_name = "Label",
  sample_id = "Barcode",
  pair_list = pair_list
)

# Make predictions
model$predict(data_frame = test_data,
              label_name = "Label",
              sample_id = "SampleID")
results <- model$results()
}

}
\seealso{
\code{\link[robencla]{Robencla}}
}
