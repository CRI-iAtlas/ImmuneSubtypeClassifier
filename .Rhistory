cat("\nApplying log2(TPM + 0.001) transformation to EBPP...\n")
for (gene in gene_cols) {
ebpp_clean[[gene]] <- log2(ebpp_clean[[gene]] + 0.001)
}
cat("\nAfter log2(x + 0.001) transformation:\n")
cat("EBPP sample genes:\n")
for (g in ebpp_sample_genes) {
cat(sprintf("  %s: [%.2f, %.2f]\n", g,
min(ebpp_clean[[g]], na.rm=TRUE),
max(ebpp_clean[[g]], na.rm=TRUE)))
}
# Verify metadata columns were NOT transformed
cat("\nMetadata verification:\n")
for (mc in existing_metadata) {
if (mc == "Label") {
cat(sprintf("  %s: %s (preserved)\n", mc,
paste(head(unique(ebpp_clean[[mc]]), 3), collapse=", ")))
} else if (mc %in% c("SampleID", "Barcode")) {
cat(sprintf("  %s: %s... (preserved)\n", mc,
paste(head(ebpp_clean[[mc]], 2), collapse=", ")))
}
}
cat("\n✓ EBPP transformed to log2 scale, metadata preserved\n\n")
# ============================================================================
# STEP 2: Stratified split - Hold out 50% of Xena for testing
# ============================================================================
set.seed(412)
# Shuffle Xena
xena_shuffled <- xena_clean[sample(nrow(xena_clean)), ]
# Split 50/50
xena_train_size <- floor(0.5 * nrow(xena_shuffled))
xena_train <- xena_shuffled[1:xena_train_size, ]
xena_test <- xena_shuffled[(xena_train_size + 1):nrow(xena_shuffled), ]
cat("=== Stratified Split ===\n")
cat("EBPP (all for training, log-transformed):", nrow(ebpp_clean), "\n")
cat("Xena training (50%):", nrow(xena_train), "\n")
cat("Xena test holdout (50%):", nrow(xena_test), "\n\n")
# Verify metadata in splits
cat("Metadata columns in all datasets:\n")
cat("  EBPP:", paste(intersect(colnames(ebpp_clean), metadata_cols), collapse=", "), "\n")
cat("  Xena train:", paste(intersect(colnames(xena_train), metadata_cols), collapse=", "), "\n")
cat("  Xena test:", paste(intersect(colnames(xena_test), metadata_cols), collapse=", "), "\n\n")
# ============================================================================
# STEP 3: Create training set (ALL EBPP + 50% Xena)
# ============================================================================
# Add batch indicators
ebpp_clean$Batch <- "EBPP"
xena_train$Batch <- "Xena_train"
xena_test$Batch <- "Xena_test"
# Combine for training
train_combined <- rbind(ebpp_clean, xena_train)
# Shuffle training data
train_combined <- train_combined[sample(nrow(train_combined)), ]
cat("=== Training Data Composition ===\n")
cat("Total training samples:", nrow(train_combined), "\n")
cat("  EBPP (log2):", sum(train_combined$Batch == "EBPP"), "\n")
cat("  Xena:", sum(train_combined$Batch == "Xena_train"), "\n\n")
cat("Label distribution in training:\n")
print(table(train_combined$Label))
cat("\nBatch distribution in training:\n")
print(table(train_combined$Batch))
cat("\n")
# Final metadata check
final_metadata <- intersect(colnames(train_combined), c(metadata_cols, "Batch"))
cat("Final metadata columns in training set:\n")
cat("  ", paste(final_metadata, collapse=", "), "\n\n")
rm(ebpp_clean, xena_clean, xena_train, xena_shuffled)
# Define metadata columns (including Batch now)
all_metadata_cols <- c("SampleID", "Barcode", "Label", "label", "Batch")
numeric_cols <- setdiff(colnames(train_combined), all_metadata_cols)
cat("Gene columns available:", length(numeric_cols), "\n")
# Calculate variance on TRAINING data only (no data leakage)
gene_variances <- apply(train_combined[, ..numeric_cols], 2, var, na.rm = TRUE)
# Select top variance genes
top_500_genes <- names(sort(gene_variances, decreasing = TRUE)[1:500])
cat("\nTop 10 genes by variance (from training data):\n")
print(head(top_500_genes, 10))
cat("\n")
# ============================================================================
# STEP 5: Create all pairs from TRAINING data only
# ============================================================================
create_all_pairs_from_genes <- function(data, gene_list) {
gene_cols <- gene_list[gene_list %in% colnames(data)]
if (length(gene_cols) < 2) {
stop("Need at least 2 genes to create pairs")
}
pair_features <- list()
for (i in 1:(length(gene_cols)-1)) {
for (j in (i+1):length(gene_cols)) {
gene1 <- gene_cols[i]
gene2 <- gene_cols[j]
pair_feat <- as.numeric(data[[gene1]] > data[[gene2]])
pair_name <- paste0(gene1, "_X_", gene2)
pair_features[[pair_name]] <- pair_feat
}
}
pair_data <- as.data.table(pair_features)
cat(sprintf("Created %d pairs from %d genes\n",
ncol(pair_data), length(gene_cols)))
return(pair_data)
}
# Create pairs from TRAINING data
all_pairs_train <- create_all_pairs_from_genes(train_combined, top_500_genes)
cat("Pair data dimensions:", nrow(all_pairs_train), "samples x",
ncol(all_pairs_train), "pairs\n\n")
# Save training set, test set,
fwrite(train_combined, '../data/formatted_full_L1000/training/train_stratified.csv.gz')
fwrite(xena_test, '../data/formatted_full_L1000/training/test_xena_holdout.csv.gz')
saveRDS(all_pairs_train, '../data/formatted_full_L1000/training/all_pairs_train.rds')
rank_pairs_xgboost <- function(pair_data, labels, top_n = 200,
nrounds = 100, early_stopping = 10) {
if (is.factor(labels)) {
label_map <- levels(labels)
labels_numeric <- as.numeric(labels) - 1
} else {
label_map <- sort(unique(labels))
labels_numeric <- match(labels, label_map) - 1
}
num_classes <- length(unique(labels_numeric))
cat(sprintf("Training XGBoost with %d pairs, %d samples, %d classes\n",
ncol(pair_data), nrow(pair_data), num_classes))
# Train/validation split within training data
set.seed(42)
n_samples <- nrow(pair_data)
train_idx <- sample(1:n_samples, size = floor(0.8 * n_samples))
val_idx <- setdiff(1:n_samples, train_idx)
dtrain <- xgb.DMatrix(
data = as.matrix(pair_data[train_idx, ]),
label = labels_numeric[train_idx]
)
dval <- xgb.DMatrix(
data = as.matrix(pair_data[val_idx, ]),
label = labels_numeric[val_idx]
)
params <- list(
objective = "multi:softmax",
num_class = num_classes,
max_depth = 4,
eta = 0.3,
subsample = 0.8,
colsample_bytree = 0.8,
eval_metric = "mlogloss"
)
watchlist <- list(train = dtrain, val = dval)
xgb_model <- xgb.train(
params = params,
data = dtrain,
nrounds = nrounds,
watchlist = watchlist,
early_stopping_rounds = early_stopping,
verbose = 1
)
importance_matrix <- xgb.importance(
feature_names = colnames(pair_data),
model = xgb_model
)
importance_matrix$gene1 <- sapply(strsplit(importance_matrix$Feature, "_X_"), `[`, 1)
importance_matrix$gene2 <- sapply(strsplit(importance_matrix$Feature, "_X_"), `[`, 2)
top_pairs <- head(importance_matrix, top_n)
cat(sprintf("\nTop %d pairs selected from %d total\n",
nrow(top_pairs), nrow(importance_matrix)))
cat(sprintf("Top pair: %s (importance: %.4f)\n",
top_pairs$Feature[1], top_pairs$Gain[1]))
return(top_pairs)
}
# Learn pairs from training data (log-EBPP + 50% Xena)
cat("=== Learning pairs from STRATIFIED TRAINING SET ===\n")
cat("Training on:", nrow(train_combined), "samples (log2-EBPP + 50% Xena)\n")
cat("Held out:", nrow(xena_test), "samples (50% Xena for testing)\n\n")
gc()
object.size(train_combined)
object.size(train_combined, units = "MB")
print(object.size(train_combined), units = "MB")
print(object.size(all_pairs_train), units = "MB")
# Include hidden objects (starting with .)
all_objs <- ls(all.names = TRUE)
sizes <- sapply(all_objs, function(x) object.size(get(x)))
sort(sizes, decreasing = TRUE)[1:20]  # Top 20
# Or get total
sum(sizes) / 1024^3  # In GB
# What R thinks it's using
gc()  # Look at the "max used" columns
# System view
library(pryr)
install.packages('pryr')
gc(full = TRUE)
top_pairs <- rank_pairs_xgboost(
pair_data = all_pairs_train,
labels = train_combined$Label,
top_n = 100,
nrounds = 50,
early_stopping = 5
)
rm(all_pairs_train)
gc()
convert_to_pair_list <- function(ranked_pairs) {
pair_list <- c()
for (i in 1:nrow(ranked_pairs)) {
pair_list <- c(pair_list, ranked_pairs$gene1[i], ranked_pairs$gene2[i])
}
return(pair_list)
}
stratified_pair_list <- convert_to_pair_list(top_pairs)
cat("\nStratified cross-platform pair list created:\n")
cat("Length:", length(stratified_pair_list), "(", length(stratified_pair_list)/2, "pairs )\n")
cat("First 10 genes:\n")
print(head(stratified_pair_list, 10))
genes_in_pairs <- unique(stratified_pair_list)
common_genes_check <- setdiff(colnames(train_combined), all_metadata_cols)
missing_genes <- setdiff(genes_in_pairs, common_genes_check)
cat("\nValidation:\n")
cat("Unique genes in pair_list:", length(genes_in_pairs), "\n")
cat("Missing genes:", length(missing_genes), "\n")
if (length(missing_genes) > 0) {
cat("ERROR: These genes are missing:\n")
print(missing_genes)
stop("Fix missing genes before proceeding")
} else {
cat("✓ All genes in pair_list exist in datasets!\n")
}
saveRDS(stratified_pair_list, '../models/pair_list_stratified.rds')
saveRDS(top_pairs, '../models/top_pairs_stratified.rds')
cat("\n=== SAVED FILES ===\n")
cat("✓ Training data: ../data/formatted_full_L1000/train_stratified.csv.gz\n")
cat("   (", nrow(train_combined), "samples:", sum(train_combined$Batch == "EBPP"),
"log2-EBPP +", sum(train_combined$Batch == "Xena_train"), "Xena )\n")
cat("   Columns:", paste(head(colnames(train_combined), 10), collapse=", "), "...\n")
cat("✓ Test data: ../data/formatted_full_L1000/test_xena_holdout.csv.gz\n")
cat("   (", nrow(xena_test), "Xena holdout samples )\n")
cat("   Columns:", paste(head(colnames(xena_test), 10), collapse=", "), "...\n")
cat("✓ Pair list: ../models/pair_list_stratified.rds\n")
cat("✓ Top pairs: ../models/top_pairs_stratified.rds\n")
cat("\n=== SUCCESS ===\n")
cat("EBPP was transformed using Xena's exact method: log2(TPM + 0.001)\n")
cat("Metadata preserved:", paste(final_metadata, collapse=", "), "\n")
cat("Pairs were learned from", nrow(train_combined), "training samples.\n")
cat("These include", sum(train_combined$Batch == "EBPP"), "log2-EBPP +",
sum(train_combined$Batch == "Xena_train"), "Xena samples.\n")
cat("", nrow(xena_test), "Xena samples held out for unbiased testing.\n")
cat("Pairs should be robust across both pipelines!\n")
# Conservative parameters for better C4/C6
conservative_params <- list(
max_depth = 6,
eta = 0.3,
nrounds = 32,
early_stopping_rounds = 2,
gamma = 0.5,
lambda = 2.0,
alpha = 0.5,
ensemble_size = 7,
sample_prop = 0.7,
feature_prop = 0.7,
subsample = 0.7
)
# Now use the cleaned pair_list
result <- build_robencla_classifier(
data_path='../data/formatted_full_L1000/training/combined_ebpp_xena.csv.gz',
test_path='../data/formatted_full_L1000/training/test_xena_holdout.csv.gz',
output_path = '../models/immune_optimized_pairs.rds',
pair_list = stratified_pair_list,
sig_list = NULL,
param_list = conservative_params,
data_mode = c("namedpairs"),
train_fraction = NULL,
seed = 412,
sample_id = "Barcode"  # Specify the sample ID column
)
all(colnames(train_combined) == colnames(xena_test))
stratified_pair_list
x <- fread('../data/formatted_full_L1000/training/test_xena_holdout.csv.gz')
all(colnames(train_combined) == colnames(x))
rm(x)
xena_test$Label
xena_test$Barcode
x <- fread('../data/formatted_full_L1000/training/test_xena_holdout.csv.gz')
x$SampleID
train_combined$SampleID
# Now use the cleaned pair_list
result <- build_robencla_classifier(
data_path='../data/formatted_full_L1000/training/combined_ebpp_xena.csv.gz',
test_path='../data/formatted_full_L1000/training/test_xena_holdout.csv.gz',
output_path = '../models/immune_optimized_pairs.rds',
pair_list = stratified_pair_list,
sig_list = NULL,
param_list = conservative_params,
data_mode = c("namedpairs"),
train_fraction = NULL,
seed = 412,
sample_id = "SampleID"  # Specify the sample ID column
)
library(data.table)
library(xgboost)
library(ImmuneSubtypeClassifier)
# ============================================================================
# STEP 1: Load cleaned datasets
# ============================================================================
ebpp_clean <- fread('../data/formatted_full_L1000/training/EBpp_pancancer_cleaned.csv.gz')
xena_clean <- fread('../data/formatted_full_L1000/training/xena_rsem_tpm_cleaned.csv.gz')
ebpp_clean$SampleID
rm(xena_clean)
rm(ebpp_clean)
library(ImmuneSubtypeClassifier)
library(ImmuneSubtypeClassifier)
library(data.table)
rsub <- fread('../data/formatted_full_L1000/Rsubread_tpm.csv.gz')
rsub$Barcode
callSubtypes <- function(rsub,
model = NULL,
model_path = NULL,
geneid = "symbol",
sampleid = 'Barcode',
labelid=NULL)
)
callSubtypes <- function(rsub,
model = NULL,
model_path = NULL,
geneid = "symbol",
sampleid = 'Barcode',
labelid=NULL)
)
callSubtypes <- function(rsub,
model = NULL,
model_path = NULL,
geneid = "symbol",
sampleid = 'Barcode')
)
results <- callSubtypes(rsub,
model = NULL,
model_path = NULL,
geneid = "symbol",
sampleid = 'Barcode',
labelid = NULL)
model <- readRDS('model/immune_optimized_pairs.rds')
model$pair_list
results <- callSubtypes(rsub,
model = NULL,
model_path = NULL,
geneid = "symbol",
sampleid = 'Barcode',
labelid = NULL)
results <- callSubtypes(rsub,
model = NULL,
model_path = NULL,
geneid = "symbol",
sampleid = 'Barcode')
save(as.vector(model$pair_list), file = 'data/gene_list.rda')
as.vector(model$pair_list)
pair_list <- as.vector(model$pair_list)
save(pair_list, file = 'data/gene_list.rda')
data(ebpp_gene, envir = environment())
sum(pair_list %in% ebpp_genes_full$Symbol)
sum(! pair_list %in% ebpp_genes_full$Symbol)
pair_list[ (! pair_list %in% ebpp_genes_full$Symbol) ]
ebpp_genes_sig
dim(ebpp_genes_sig)
dim(ebpp_genes_full)
ebpp_genes_full[ebpp_genes_full$Symbol == 'STAT-1']
ebpp_genes_full[ebpp_genes_full$Symbol == 'STAT1']
pair_list[ (! pair_list %in% ebpp_genes_full$Symbol) ]
ebpp_genes_full[ebpp_genes_full$Symbol == 'STAT1.1']
ebpp_genes_full[ebpp_genes_full$Symbol == 'STAT1-1']
ebpp_genes_full[ebpp_genes_full$Symbol == 'STAT1']
ebpp_genes_full[ebpp_genes_full$Symbol == 'STAT1]
ebpp_genes_full[ebpp_genes_full$Symbol == 'STAT1']
pair_list[ (! pair_list %in% colnames(rsub)) ]
# Check what STAT1 variants exist in rsub
stat1_variants <- grep("^STAT1", colnames(rsub), value = TRUE)
cat("STAT1 variants in rsub:\n")
print(stat1_variants)
# Check what's in the pair list
stat1_in_pairs <- grep("^STAT1", pair_list, value = TRUE)
cat("\nSTAT1 variants in pair_list:\n")
print(stat1_in_pairs)
# Apply the same normalization used in training data
normalize_gene_names <- function(gene_names) {
gene_names <- gsub(" ", "_", gene_names)
gene_names <- gsub("-", "_", gene_names)
gene_names <- gsub("\\.", "_", gene_names)  # Convert dots to underscores
return(gene_names)
}
# Store original names for reference
rsub_original_names <- colnames(rsub)
# Normalize column names
colnames(rsub) <- normalize_gene_names(colnames(rsub))
# Verify the fix
stat1_after <- grep("^STAT1", colnames(rsub), value = TRUE)
cat("STAT1 variants in rsub after normalization:\n")
print(stat1_after)
# Should now show: "STAT1" "STAT1_1"
# Final check
missing_genes <- unique(pair_list[!(pair_list %in% colnames(rsub))])
cat("\nMissing genes after normalization:\n")
print(missing_genes)
cat("Count:", length(missing_genes), "\n")
if (length(missing_genes) == 0) {
cat("\n✓ All genes in pair_list now exist in rsub!\n")
} else {
cat("\n✗ Still missing", length(missing_genes), "genes\n")
cat("Examples:", head(missing_genes, 10), "\n")
}
results <- callSubtypes(rsub,
model = model,
model_path = NULL,
geneid = "symbol",
sampleid = 'Barcode')
model$predict(
data_frame = rsub,
label_name = 'Label',
sample_id = 'Barcode'
)
results <- callSubtypes(rsub,
model = model,
model_path = NULL,
geneid = "symbol",
sampleid = 'Barcode')
results <- model$results()
output <- data.frame(
SampleIDs = results$SampleID,
BestCall = as.integer(gsub("C", "", results$BestCall)),
stringsAsFactors = FALSE
)
View(output)
results
rsub$Label
output <- data.frame(
SampleIDs = results$SampleID,
BestCall = as.integer(gsub("C", "", results$BestCall)),
stringsAsFactors = FALSE
)
table(results$BestCalls, rsub$Label)
labels <- model$test_label
table(results$BestCalls, labels)
table(results$BestCalls, labels)
model$test_label
rsub$Label
model$predict(
data_frame = rsub,
label_name = 'Label',
sample_id = 'Barcode'
)
model$test_label
results <- model$results()
results$Label
results$BestCalls
table(results$BestCalls, results$Label)
score_cols <- grep("^C[1-6]$", colnames(results), value = TRUE)
if (length(score_cols) > 0) {
scores <- results[, score_cols, drop = FALSE]
colnames(scores) <- gsub("C", "", colnames(scores))
scores <- scores[, as.character(1:6)]
output <- cbind(output, scores)
}
score_cols
cat(sprintf("\nConfusion Matrix (%s data):\n", eval_label))
cat(sprintf("\nConfusion Matrix (%s data):\n", ))
print(table(Predicted = results$BestCalls, Actual = model$test_label))
print(model$classification_metrics())
cat(sprintf("\nConfusion Matrix (%s data):\n", 'test'))
print(table(Predicted = results$BestCalls, Actual = model$test_label))
cat("\nClassification Metrics:\n")
print(model$classification_metrics())
conf_matrix <- matrix(c(
1581, 101, 76, 17, 0, 2,
83, 1623, 22, 9, 0, 1,
71, 49, 1752, 40, 4, 10,
46, 41, 69, 588, 13, 4,
0, 0, 3, 9, 357, 0,
14, 17, 21, 1, 0, 56
), nrow=6, byrow=TRUE)
rownames(conf_matrix) <- c("C1", "C2", "C3", "C4", "C5", "C6")
colnames(conf_matrix) <- c("1", "2", "3", "4", "5", "6")
# Calculate per-class metrics
calculate_metrics <- function(conf_mat, class_idx) {
tp <- conf_mat[class_idx, class_idx]
fp <- sum(conf_mat[class_idx, ]) - tp
fn <- sum(conf_mat[, class_idx]) - tp
tn <- sum(conf_mat) - tp - fp - fn
sensitivity <- tp / (tp + fn)
precision <- tp / (tp + fp)
f1 <- 2 * (precision * sensitivity) / (precision + sensitivity)
return(c(Sensitivity=sensitivity, Precision=precision, F1=f1))
}
for (i in 1:6) {
metrics <- calculate_metrics(conf_matrix, i)
cat(sprintf("C%d: Sens=%.3f, Prec=%.3f, F1=%.3f\n",
i, metrics[1], metrics[2], metrics[3]))
}
# Overall accuracy
overall_acc <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat(sprintf("\nOverall Accuracy: %.3f\n", overall_acc))
conf_matrix <- table(Predicted = results$BestCalls, Actual = model$test_label)
rownames(conf_matrix) <- c("C1", "C2", "C3", "C4", "C5", "C6")
colnames(conf_matrix) <- c("1", "2", "3", "4", "5", "6")
# Calculate per-class metrics
calculate_metrics <- function(conf_mat, class_idx) {
tp <- conf_mat[class_idx, class_idx]
fp <- sum(conf_mat[class_idx, ]) - tp
fn <- sum(conf_mat[, class_idx]) - tp
tn <- sum(conf_mat) - tp - fp - fn
sensitivity <- tp / (tp + fn)
precision <- tp / (tp + fp)
f1 <- 2 * (precision * sensitivity) / (precision + sensitivity)
return(c(Sensitivity=sensitivity, Precision=precision, F1=f1))
}
for (i in 1:6) {
metrics <- calculate_metrics(conf_matrix, i)
cat(sprintf("C%d: Sens=%.3f, Prec=%.3f, F1=%.3f\n",
i, metrics[1], metrics[2], metrics[3]))
}
# Overall accuracy
overall_acc <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat(sprintf("\nOverall Accuracy: %.3f\n", overall_acc))
