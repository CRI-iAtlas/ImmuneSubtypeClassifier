C1=c("B2M","COL3A1","B2M","COL1A2","COL1A2","HLA-B","COL3A1","HLA-B","APOE","COL6A3","APOE","SDC1","APOE","COL6A1","APOE","MMP14","APOE","MMP2","COL1A2","SPARC")
)
names(pair_list)
paste(unlist(x), sep = ',', collapse = )
paste(unlist(x), collapse = ',')
paste(unlist(x), collapse = '\",\"')
pair_list <- list(
C1=c("B2M","COL3A1","B2M","COL1A2","COL1A2","HLA-B","COL3A1","HLA-B","APOE","COL6A3","APOE","SDC1","APOE","COL6A1","APOE","MMP14","APOE","MMP2","COL1A2","SPARC"),
C2=c("B2M\",\"COL3A1\",\"B2M\",\"COL1A2\",\"COL1A2\",\"HLA-B\",\"COL3A1\",\"HLA-B\",\"APOE\",\"COL6A3\",\"APOE\",\"SDC1\",\"APOE\",\"COL6A1\",\"APOE\",\"MMP14\",\"APOE\",\"MMP2\",\"COL1A2\",\"SPARC")
)
pair_list$C2
paste(unlist(x), collapse = "','")
df1 <- df[df$Label == 'C2',]
df1 <- as.data.frame( df1[order(df1$Score, decreasing = T),] )
x <- lapply(1:10, function(a) c( as.character(df1[a, 'Feature1']),
as.character(df1[a, 'Feature2']) ))
paste(unlist(x), collapse = "','")
pair_list <- list(
C1=c("B2M","COL3A1","B2M","COL1A2","COL1A2","HLA-B","COL3A1","HLA-B","APOE","COL6A3","APOE","SDC1","APOE","COL6A1","APOE","MMP14","APOE","MMP2","COL1A2","SPARC"),
C2=c('IFI27','RHOB','IFI6','RHOB','IFI27','LRP1','IFI27','NPC2','IFI6','NPC2','IFI27','TAGLN','RHOB','STAT1','IFI6','LRP1','IFI27','IGFBP3','IFI27','IGFBP4')
)
label <- 'C3'
df1 <- df[df$Label == label,]
df1 <- as.data.frame( df1[order(df1$Score, decreasing = T),] )
x <- lapply(1:10, function(a) c( as.character(df1[a, 'Feature1']),
as.character(df1[a, 'Feature2']) ))
paste(unlist(x), collapse = "','")
label <- 'C4'
df1 <- df[df$Label == label,]
df1 <- as.data.frame( df1[order(df1$Score, decreasing = T),] )
x <- lapply(1:10, function(a) c( as.character(df1[a, 'Feature1']),
as.character(df1[a, 'Feature2']) ))
paste(unlist(x), collapse = "','")
source("~/Code/ImmuneSubtypeClassifier/R/feature_search.R", echo=TRUE)
label <- 'C5'
df1 <- df[df$Label == label,]
df1 <- as.data.frame( df1[order(df1$Score, decreasing = T),] )
x <- lapply(1:10, function(a) c( as.character(df1[a, 'Feature1']),
as.character(df1[a, 'Feature2']) ))
paste(unlist(x), collapse = "','")
label <- 'C6'
df1 <- df[df$Label == label,]
df1 <- as.data.frame( df1[order(df1$Score, decreasing = T),] )
x <- lapply(1:10, function(a) c( as.character(df1[a, 'Feature1']),
as.character(df1[a, 'Feature2']) ))
paste(unlist(x), collapse = "','")
df5 <- feature_search(data = ebpp,
label_col_name = 'Label',
sample_col_name = 'Barcode',
this_label = 'C6',
this_thresh = 0.33)
df6 <- feature_search(data = ebpp,
label_col_name = 'Label',
sample_col_name = 'Barcode',
this_label = 'C6',
this_thresh = 0.33)
feature_search <- function(data,  # samples in rows, features in cols
label_col_name, # column name containing labels
sample_col_name,  # column name containing sample barcodes / sample names
this_label,  # the base label to compare to others
this_thresh # will not report feature-pairs with prop_diffs below thresh
) {
# recorded diff
diff_list <- c()
# the pair count/index
k <- 1
# list of results
resl <- list()
# the unique labels in the data
labels <- as.vector(data[label_col_name])[[1]]
labels <- sort(unique(labels))
#  index into this cluster
idx <- data[,label_col_name] == this_label
jdx <- data[,label_col_name] != this_label
cidx <- !(colnames(data) %in% c(label_col_name,sample_col_name))
cjdx <- !(colnames(data) %in% c(label_col_name,sample_col_name))
# data labeled as THIS cluster
labdat <- data[idx, cidx]
# data labels as NOT THIS cluster
notdat <- data[jdx,cjdx]
# number of samples in each category
m <- sum(idx)
n <- sum(jdx)
# number of genes in the table
ngenes <- ncol(labdat)
# for each pair of genes
for (i in 1:(ngenes-1)){
for (j in (i+1):(ngenes)) {
# proportion of samples showing pattern gene1 > gene2
prop1 <- (sum(labdat[,i] > labdat[,j])/m) # proportion i>j in this cluster
prop2 <- (sum(notdat[,i] > notdat[,j])/n) # proportion i>j in others
# if the difference in proportions, between cluster and not-cluster
# is greater than 75%, then record the gene pair.
if (abs(prop1-prop2) > this_thresh) {
# next line: distnance between the two genes, within sample grouping.
dist1 <- as.vector(labdat[,i] - labdat[,j])[[1]]
dist2 <- as.vector(notdat[,i] - notdat[,j])[[1]]
t_dist1   <- t.test(dist1, na.rm = T)$statistic
t_dist2   <- t.test(dist2, na.rm = T)$statistic
med_dist1 <- median(dist1, na.rm = T)
med_dist2 <- median(dist2, na.rm=T)
avg_dist1 <- mean(dist1, na.rm = T)
avg_dist2 <- mean(dist2, na.rm=T)
n1        <- length(dist1)
n2        <- length(dist2)
score <- abs(prop1-prop2)*(-1 * mean(dist1) * mean(dist2))
g1 <- colnames(labdat)[i]
g2 <- colnames(labdat)[j]
if (score > 0) {
#capture this result
resl[[k]] <- c(this_label,
k,i,j,
g1,g2,
prop1,prop2,
(prop1-prop2),
score,
t_dist1, t_dist2,
med_dist1, med_dist2,
avg_dist1, avg_dist2,
n1, n2) # want diff to be 1 or -1
k <- k+1
}
} else {
diff_list <- c(diff_list, abs(prop1-prop2))
}
}
} # end gene pair loop
if (length(resl) > 0) {
df <- do.call('rbind', resl)
colnames(df) <- c('Label','k','i','j','Feature1','Feature2',
'Prop1','Prop2','PropDiff','Score','T_dist1','T_dist2',
'MedDist1','MedDist2','AvgDist1','AvgDist2','N1','N2')
return(df)
} else {
return(diff_list)
}
}
df6 <- feature_search(data = ebpp,
label_col_name = 'Label',
sample_col_name = 'Barcode',
this_label = 'C6',
this_thresh = 0.33)
ebpp$Label
sapply(ebpp$Label, function(a) paste0('C',a))
ebpp$Label <- sapply(ebpp$Label, function(a) paste0('C',a))
df6 <- feature_search(data = ebpp,
label_col_name = 'Label',
sample_col_name = 'Barcode',
this_label = 'C6',
this_thresh = 0.33)
df <- rbind(df1,df2,df3,df4,df5,df6)
df <- rbind(df, df6)
feature_search <- function(data,  # samples in rows, features in cols
label_col_name, # column name containing labels
sample_col_name,  # column name containing sample barcodes / sample names
this_label,  # the base label to compare to others
this_thresh # will not report feature-pairs with prop_diffs below thresh
) {
# recorded diff
diff_list <- c()
# the pair count/index
k <- 1
# list of results
resl <- list()
# the unique labels in the data
labels <- as.vector(data[label_col_name])[[1]]
labels <- sort(unique(labels))
#  index into this cluster
idx <- data[,label_col_name] == this_label
jdx <- data[,label_col_name] != this_label
cidx <- !(colnames(data) %in% c(label_col_name,sample_col_name))
cjdx <- !(colnames(data) %in% c(label_col_name,sample_col_name))
# data labeled as THIS cluster
labdat <- data[idx, cidx]
# data labels as NOT THIS cluster
notdat <- data[jdx,cjdx]
# number of samples in each category
m <- sum(idx)
n <- sum(jdx)
# number of genes in the table
ngenes <- ncol(labdat)
# for each pair of genes
for (i in 1:(ngenes-1)){
for (j in (i+1):(ngenes)) {
# proportion of samples showing pattern gene1 > gene2
prop1 <- (sum(labdat[,i] > labdat[,j])/m) # proportion i>j in this cluster
prop2 <- (sum(notdat[,i] > notdat[,j])/n) # proportion i>j in others
# if the difference in proportions, between cluster and not-cluster
# is greater than 75%, then record the gene pair.
if (abs(prop1-prop2) > this_thresh) {
# next line: distnance between the two genes, within sample grouping.
dist1 <- as.vector(labdat[,i] - labdat[,j])[[1]]
dist2 <- as.vector(notdat[,i] - notdat[,j])[[1]]
t_dist1   <- t.test(dist1, na.rm = T)$statistic
t_dist2   <- t.test(dist2, na.rm = T)$statistic
med_dist1 <- median(dist1, na.rm = T)
med_dist2 <- median(dist2, na.rm=T)
avg_dist1 <- mean(dist1, na.rm = T)
avg_dist2 <- mean(dist2, na.rm=T)
n1        <- length(dist1)
n2        <- length(dist2)
score <- abs(prop1-prop2)*(-1 * mean(dist1) * mean(dist2))
g1 <- colnames(labdat)[i]
g2 <- colnames(labdat)[j]
if (score > 0) {
#capture this result
resl[[k]] <- c(this_label,
k,i,j,
g1,g2,
prop1,prop2,
(prop1-prop2),
score,
t_dist1, t_dist2,
med_dist1, med_dist2,
avg_dist1, avg_dist2,
n1, n2) # want diff to be 1 or -1
k <- k+1
}
} else {
diff_list <- c(diff_list, abs(prop1-prop2))
}
}
} # end gene pair loop
if (length(resl) > 0) {
df <- do.call('rbind', resl)
colnames(df) <- c('Label','k','i','j','Feature1','Feature2',
'Prop1','Prop2','PropDiff','Score','T_dist1','T_dist2',
'MedDist1','MedDist2','AvgDist1','AvgDist2','N1','N2')
return(df)
} else {
return(diff_list)
}
}
df1 <- feature_search(data = ebpp,
label_col_name = 'Label',
sample_col_name = 'Barcode',
this_label = 'C1',
this_thresh = 0.33)
df2 <- feature_search(data = ebpp,
label_col_name = 'Label',
sample_col_name = 'Barcode',
this_label = 'C2',
this_thresh = 0.33)
df3 <- feature_search(data = ebpp,
label_col_name = 'Label',
sample_col_name = 'Barcode',
this_label = 'C3',
this_thresh = 0.33)
df4 <- feature_search(data = ebpp,
label_col_name = 'Label',
sample_col_name = 'Barcode',
this_label = 'C4',
this_thresh = 0.33)
df5 <- feature_search(data = ebpp,
label_col_name = 'Label',
sample_col_name = 'Barcode',
this_label = 'C5',
this_thresh = 0.33)
df6 <- feature_search(data = ebpp,
label_col_name = 'Label',
sample_col_name = 'Barcode',
this_label = 'C6',
this_thresh = 0.33)
df <- rbind(df1,df2,df3,df4,df5,df6)
write.csv(df, file = '/data/robencla_work/ebpp_487_features.csv')
df <- readr::read_csv('/data/robencla_work/ebpp_487_features.csv')
label <- 'C1'
df1 <- df[df$Label == label,]
df1 <- as.data.frame( df1[order(df1$Score, decreasing = T),] )
x <- lapply(1:10, function(a) c( as.character(df1[a, 'Feature1']),
as.character(df1[a, 'Feature2']) ))
paste(unlist(x), collapse = "','")
label <- 'C2'
df1 <- df[df$Label == label,]
df1 <- as.data.frame( df1[order(df1$Score, decreasing = T),] )
x <- lapply(1:10, function(a) c( as.character(df1[a, 'Feature1']),
as.character(df1[a, 'Feature2']) ))
paste(unlist(x), collapse = "','")
label <- 'C5'
df1 <- df[df$Label == label,]
df1 <- as.data.frame( df1[order(df1$Score, decreasing = T),] )
x <- lapply(1:10, function(a) c( as.character(df1[a, 'Feature1']),
as.character(df1[a, 'Feature2']) ))
paste(unlist(x), collapse = "','")
label <- 'C6'
df1 <- df[df$Label == label,]
df1 <- as.data.frame( df1[order(df1$Score, decreasing = T),] )
x <- lapply(1:10, function(a) c( as.character(df1[a, 'Feature1']),
as.character(df1[a, 'Feature2']) ))
paste(unlist(x), collapse = "','")
pair_list <- list(
C1=c("B2M","COL3A1","B2M","COL1A2","COL1A2","HLA-B","COL3A1","HLA-B","APOE","COL6A3","APOE","SDC1","APOE","COL6A1","APOE","MMP14","APOE","MMP2","COL1A2","SPARC"),
C2=c('IFI27','RHOB','IFI6','RHOB','IFI27','LRP1','IFI27','NPC2','IFI6','NPC2','IFI27','TAGLN','RHOB','STAT1','IFI6','LRP1','IFI27','IGFBP3','IFI27','IGFBP4')
C3=c('COL3A1','SPARC','IGFBP4','JUP','CD59','JUP','NPC2','SLC25A5','IFI27','NPC2','IGFBP4','PFN1','HNRNPA2B1','IGFBP4','CCT5','NPC2','IFI27','MET','IGFBP4','TPI1'),
pair_list <- list(
C1=c("B2M","COL3A1","B2M","COL1A2","COL1A2","HLA-B","COL3A1","HLA-B","APOE","COL6A3","APOE","SDC1","APOE","COL6A1","APOE","MMP14","APOE","MMP2","COL1A2","SPARC"),
C2=c('IFI27','RHOB','IFI6','RHOB','IFI27','LRP1','IFI27','NPC2','IFI6','NPC2','IFI27','TAGLN','RHOB','STAT1','IFI6','LRP1','IFI27','IGFBP3','IFI27','IGFBP4'),
C3=c('COL3A1','SPARC','IGFBP4','JUP','CD59','JUP','NPC2','SLC25A5','IFI27','NPC2','IGFBP4','PFN1','HNRNPA2B1','IGFBP4','CCT5','NPC2','IFI27','MET','IGFBP4','TPI1'),
C4=c('APOE','COL3A1','APOE','COL1A2','COL3A1','SPARC','APOC1','DSP','COL1A2','SPARC','APOC1','JUP','APOC1','COL6A3','APOC1','LYZ','APOC1','SDC1','DSP','RHOB'),
C5=c('APOE','FN1','FN1','SPARC','APOE','COL3A1','APOE','COL1A2','B2M','SPARC','APOE','B2M','FN1','SLC1A3','COL3A1','SLC1A3','APOE','HLA-B','COL1A2','SLC1A3'),
C6=c('B2M','COL3A1','B2M','COL1A2','COL6A3','ENO1','BSG','COL6A3','COL6A3','HNRNPA2B1','COL6A3','MYL6','BSG','COL6A1','COL6A3','DSP','BSG','MMP2','JUP','MMP2')
)
emod <- trainRobencla <- function(ebpp,
label_name='ClusterLabel',
sample_id = 'SampleBarcode',
pair_list)
)
emod <- trainRobencla(ebpp,
label_name = 'ClusterLabel',
sample_id  = 'SampleBarcode',
pair_list)
trainRobencla <- function(data,
label_name='ClusterLabel',
sample_id = 'SampleBarcode',
pair_list
) {
obj_name <- Sys.time()
# Our classifier object named Anne.  Hi Anne!
mod <- Robencla$new(obj_name)
# XGBoost parameters to pass to each sub-classifier in the ensembles
params <- list(
max_depth=12,    # "height" of the tree, 6 is actually default. I think about 12 seems better.  (xgboost parameter)
eta=0.3,        # this is the learning rate. smaller values slow it down, more conservative   (xgboost parameter)
nrounds=64,     # number of rounds of training, lower numbers less overfitting (potentially)  (xgboost parameter)
early_stopping_rounds=2, # number of rounds without improvment stops the training (xgboost early_stopping_rounds)
nthreads=4,     # parallel threads
gamma=0.2,        # min loss required to again split a leaf node. higher ~ more conservative (xgboost parameter)
lambda=1.2,     # L2 regularization term on weights, higher number ~ more conservative (xgboost parameter)
alpha=0.2,      # L1 regularization term on weights. higher number ~ more conservative (xgboost parameter)
size=11,        # Size of the ensemble, per binary prediction
sample_prop=0.8, # The percentage of data used to train each ensemble member.
feature_prop=0.8, # The percentage of data used to train each ensemble member.
subsample=0.8,    # the xgboost machines subsample at this rate.
combine_function='median'  # How the ensemble should be combined. Only median currently.
verbose=0)
# XGBoost parameters to pass to each sub-classifier in the ensembles
params <- list(
max_depth=12,    # "height" of the tree, 6 is actually default. I think about 12 seems better.  (xgboost parameter)
eta=0.3,        # this is the learning rate. smaller values slow it down, more conservative   (xgboost parameter)
nrounds=64,     # number of rounds of training, lower numbers less overfitting (potentially)  (xgboost parameter)
early_stopping_rounds=2, # number of rounds without improvment stops the training (xgboost early_stopping_rounds)
nthreads=4,     # parallel threads
gamma=0.2,        # min loss required to again split a leaf node. higher ~ more conservative (xgboost parameter)
lambda=1.2,     # L2 regularization term on weights, higher number ~ more conservative (xgboost parameter)
alpha=0.2,      # L1 regularization term on weights. higher number ~ more conservative (xgboost parameter)
size=11,        # Size of the ensemble, per binary prediction
sample_prop=0.8, # The percentage of data used to train each ensemble member.
feature_prop=0.8, # The percentage of data used to train each ensemble member.
subsample=0.8,    # the xgboost machines subsample at this rate.
combine_function='median',  # How the ensemble should be combined. Only median currently.
verbose=0)
emod <- trainRobencla(ebpp,
label_name = 'ClusterLabel',
sample_id  = 'SampleBarcode',
pair_list)
trainRobencla <- function(data,
label_name='ClusterLabel',
sample_id = 'SampleBarcode',
pair_list
) {
obj_name <- Sys.time()
# Our classifier object named Anne.  Hi Anne!
mod <- Robencla$new(obj_name)
# XGBoost parameters to pass to each sub-classifier in the ensembles
params <- list(
max_depth=12,    # "height" of the tree, 6 is actually default. I think about 12 seems better.  (xgboost parameter)
eta=0.3,        # this is the learning rate. smaller values slow it down, more conservative   (xgboost parameter)
nrounds=64,     # number of rounds of training, lower numbers less overfitting (potentially)  (xgboost parameter)
early_stopping_rounds=2, # number of rounds without improvment stops the training (xgboost early_stopping_rounds)
nthreads=4,     # parallel threads
gamma=0.2,        # min loss required to again split a leaf node. higher ~ more conservative (xgboost parameter)
lambda=1.2,     # L2 regularization term on weights, higher number ~ more conservative (xgboost parameter)
alpha=0.2,      # L1 regularization term on weights. higher number ~ more conservative (xgboost parameter)
size=11,        # Size of the ensemble, per binary prediction
sample_prop=0.8, # The percentage of data used to train each ensemble member.
feature_prop=0.8, # The percentage of data used to train each ensemble member.
subsample=0.8,    # the xgboost machines subsample at this rate.
combine_function='median',  # How the ensemble should be combined. Only median currently.
verbose=0)
###More on the xgboost parameters: https://xgboost.readthedocs.io/en/latest/parameter.html
# First we use the training data
mod$train (data_frame=data,
label_name=label_name,
sample_id=sample_id,
data_mode=c('namedpairs'), # allpairs,pairs,sigpairs,quartiles,tertiles,binarize,ranks,original #
signatures=NULL,
pair_list=pair_list,  # subset to these genes.
params=params)
return(mod)
}
emod <- trainRobencla(ebpp,
label_name = 'ClusterLabel',
sample_id  = 'SampleBarcode',
pair_list)
library(robencla)
devtools::install_github("gibbsdavidl/robencla", force = F)
install.packages('XML')
install.packages('plotROC')
devtools::install_github("gibbsdavidl/robencla", force = F)
library(robencla)
trainRobencla <- function(data,
label_name='ClusterLabel',
sample_id = 'SampleBarcode',
pair_list
) {
obj_name <- Sys.time()
# Our classifier object named Anne.  Hi Anne!
mod <- Robencla$new(obj_name)
# XGBoost parameters to pass to each sub-classifier in the ensembles
params <- list(
max_depth=12,    # "height" of the tree, 6 is actually default. I think about 12 seems better.  (xgboost parameter)
eta=0.3,        # this is the learning rate. smaller values slow it down, more conservative   (xgboost parameter)
nrounds=64,     # number of rounds of training, lower numbers less overfitting (potentially)  (xgboost parameter)
early_stopping_rounds=2, # number of rounds without improvment stops the training (xgboost early_stopping_rounds)
nthreads=4,     # parallel threads
gamma=0.2,        # min loss required to again split a leaf node. higher ~ more conservative (xgboost parameter)
lambda=1.2,     # L2 regularization term on weights, higher number ~ more conservative (xgboost parameter)
alpha=0.2,      # L1 regularization term on weights. higher number ~ more conservative (xgboost parameter)
size=11,        # Size of the ensemble, per binary prediction
sample_prop=0.8, # The percentage of data used to train each ensemble member.
feature_prop=0.8, # The percentage of data used to train each ensemble member.
subsample=0.8,    # the xgboost machines subsample at this rate.
combine_function='median',  # How the ensemble should be combined. Only median currently.
verbose=0)
###More on the xgboost parameters: https://xgboost.readthedocs.io/en/latest/parameter.html
# First we use the training data
mod$train (data_frame=data,
label_name=label_name,
sample_id=sample_id,
data_mode=c('namedpairs'), # allpairs,pairs,sigpairs,quartiles,tertiles,binarize,ranks,original #
signatures=NULL,
pair_list=pair_list,  # subset to these genes.
params=params)
return(mod)
}
# define the pair list; top 10 scoring pairs in each class
pair_list <- list(
C1=c("B2M","COL3A1","B2M","COL1A2","COL1A2","HLA-B","COL3A1","HLA-B","APOE","COL6A3","APOE","SDC1","APOE","COL6A1","APOE","MMP14","APOE","MMP2","COL1A2","SPARC"),
C2=c('IFI27','RHOB','IFI6','RHOB','IFI27','LRP1','IFI27','NPC2','IFI6','NPC2','IFI27','TAGLN','RHOB','STAT1','IFI6','LRP1','IFI27','IGFBP3','IFI27','IGFBP4'),
C3=c('COL3A1','SPARC','IGFBP4','JUP','CD59','JUP','NPC2','SLC25A5','IFI27','NPC2','IGFBP4','PFN1','HNRNPA2B1','IGFBP4','CCT5','NPC2','IFI27','MET','IGFBP4','TPI1'),
C4=c('APOE','COL3A1','APOE','COL1A2','COL3A1','SPARC','APOC1','DSP','COL1A2','SPARC','APOC1','JUP','APOC1','COL6A3','APOC1','LYZ','APOC1','SDC1','DSP','RHOB'),
C5=c('APOE','FN1','FN1','SPARC','APOE','COL3A1','APOE','COL1A2','B2M','SPARC','APOE','B2M','FN1','SLC1A3','COL3A1','SLC1A3','APOE','HLA-B','COL1A2','SLC1A3'),
C6=c('B2M','COL3A1','B2M','COL1A2','COL6A3','ENO1','BSG','COL6A3','COL6A3','HNRNPA2B1','COL6A3','MYL6','BSG','COL6A1','COL6A3','DSP','BSG','MMP2','JUP','MMP2')
)
# read in formatted data
ebpp <- readr::read_csv('/data/robencla_work/data/formatted_iatlas_485/EBpp_pancancer.csv')
ebpp$Label <- sapply(ebpp$Label, function(a) paste0('C',a))
emod <- trainRobencla(ebpp,
label_name = 'ClusterLabel',
sample_id  = 'SampleBarcode',
pair_list)
emod <- trainRobencla(ebpp,
label_name = 'Label',
sample_id  = 'Barcode',
pair_list)
emod$predict(data_frame = ebpp)
emod$results()
table ( emod$results()$BestCalls , ebpp$Label )
emod$results(include_label = T)
res0 <- emod$results(include_label = T)
View(res0)
table(res0$BestCalls, emod$test_label)
emod$test_label
emod$predict(data_frame = ebpp,
label_name = 'Label',
sample_id  = 'Barcode',
)
table(res0$BestCalls, emod$test_label)
emod$classification_metrics()
ebpp$Label
emod$classification_metrics()
emod$train_data[1:5,1:5]
dim(emod$train_data)
dim(emod$data_colnames)
ebpp <- as.data.table(ebpp)
ebpp$Label <- sapply(ebpp$Label, function(a) paste0('C',a))
emod$accuracy()
emod$ensbl[[1]]
emod$ensbl[[1]]$train_data
emod$ensbl[[1]]$pair_list
emod$ensbl[[2]]$train_data
emod <- trainRobencla(ebpp,
label_name = 'Label',
sample_id  = 'Barcode',
pair_list)
# read in formatted data
ebpp <- readr::read_csv('/data/robencla_work/data/formatted_iatlas_485/EBpp_pancancer.csv')
ebpp <- as.data.table(ebpp)
ebpp$Label <- sapply(ebpp$Label, function(a) paste0('C',a))
emod <- trainRobencla(ebpp,
label_name = 'Label',
sample_id  = 'Barcode',
pair_list)
emod$predict(data_frame = ebpp,
label_name = 'Label',
sample_id  = 'Barcode')
res0 <- emod$results(include_label = T)
table(res0$BestCalls, emod$test_label)
emod$classification_metrics()
ebpp <- readr::read_csv('/data/robencla_work/data/formatted_iatlas_485/EBpp_pancancer.csv')
#ebpp <- as.data.table(ebpp)
ebpp$Label <- sapply(ebpp$Label, function(a) paste0('C',a))
emod <- trainRobencla(ebpp,
label_name = 'Label',
sample_id  = 'Barcode',
pair_list)
emod$predict(data_frame = ebpp,
label_name = 'Label',
sample_id  = 'Barcode')
res0 <- emod$results(include_label = T)
table(res0$BestCalls, emod$test_label)
emod$classification_metrics()
